# Go Beyond the Numbers Translate Data into Insights

## What I took from those activities? - Let's see:
In this course, I learned how to find the story within data and compellingly tell that story. With visualizations to be a major element of the course, I learned various visualization types such as `box plots`, `histograms`, `heat maps`, and `geo maps`, which type is more suitable for each scenario, and how to `interpret the visualizations` I have created. For this cause, I had to work in-depth with key Python libraries such as `matplotlib.pyplot`, `seaborn`, and `plotly` as well as with the visualization software `Tableau`.

This course delves into the procedure of `Exploratory Data Analysis (EDA)` segmenting it into 6 fundamental stages. Following the course, I quickly learned that EDA is not like a cake recipe. It is not a step-by-step process you follow. Instead, the six practices of EDA are iterative and non-sequential.

- `Discovering`: The process data professionals use to familiarize themselves with the data so they can start conceptualizing how to use it.
- `Cleaning`: The process of removing errors that might distort your data or make it less useful.
- `Structuring`: The process of taking raw data and organizing or transforming it to be more easily visualized, explained, or modeled.
- `Joining`: The process of augmenting data by adding values from other datasets.
- `Validating`: The process of verifying that the data is consistent and high-quality.
- `Presenting`: The process of making a cleaned dataset available to others for analysis or further modeling.

The course drove me through every one of the 6 practices thoroughly. I learned how to use advanced Python code and techniques to understand the data format, `manipulate datetime variables`, and use structuring methods to establish order in my dataset.

Additionally, I faced the challenge of `missing data`, `duplicated data`, and `outliers`.

- I learned how to identify duplicated elements along with how and when to proceed with deduplication methods.
- I gained proficiency in managing missing data, employing various techniques to address them depending on their impact on my dataset.
- Finally, I learned how to work with outliers, how to detect them and determine whether to remove, reassign, or retain them in my dataset depending on the influence they could have on my analysis results.

Furthermore, I also practice `label encoding` and `one-hot encoding`, learning how to change categorical data to numerical data, the pros and cons of each approach, and how to decide which encoding method to follow.

